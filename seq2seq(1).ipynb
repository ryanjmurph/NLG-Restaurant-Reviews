{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6qrJk6sa3B-",
        "outputId": "6580ede2-ccb3-408a-d7fd-32c61a901f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4wHDt_7bNp6"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5DZK9jObbhz"
      },
      "outputs": [],
      "source": [
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z_!?]+\", r\" \", s)\n",
        "    return s.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtO15ZSblolt"
      },
      "outputs": [],
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    reverse = True\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open(\"/content/drive/MyDrive/MRPRYA002/language.txt\", encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "    print(\"yes\")\n",
        "    print(pairs[1])\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if True == False:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKzIc9hllaNi"
      },
      "outputs": [],
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', False)\n",
        "print(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Fbz-UwFsfNqv"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 15\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_yeEWJQvPQB"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=3, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout_p)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2g15Ku9XQRcb"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
        "\n",
        "    def forward_step(self, input, hidden):\n",
        "        output = self.embedding(input)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output)\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pP9FjCPcPlFw"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        query = query[-1].unsqueeze(1)  # shape: (batch_size, 1, hidden_size)\n",
        "\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)  # shape: (batch_size, 1, seq_len)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)  # shape: (batch_size, 1, seq_len)\n",
        "        context = torch.bmm(weights, keys)  # shape: (batch_size, 1, hidden_size)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, num_layers=3, input_dropout_p=0.1, output_dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size * 2, hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.input_dropout = nn.Dropout(input_dropout_p)\n",
        "        self.output_dropout = nn.Dropout(output_dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1)  # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.input_dropout(self.embedding(input))\n",
        "\n",
        "        # Take the last layer's hidden state\n",
        "        query = hidden[-1].unsqueeze(1)  # shape: (batch_size, 1, hidden_size)\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.output_dropout(output)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJMWFYi7btcg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wkbkkQzwMpc"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "def get_dataloader(batch_size):\n",
        "    input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = indexesFromSentence(input_lang, inp)\n",
        "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return input_lang, output_lang, train_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9z_aJsWQwQjJ"
      },
      "outputs": [],
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8jkgZXLwWhe"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvlC1D5RwbdN"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "          print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                         epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "        # Save the best model immediately when a new best loss is encountered\n",
        "        if loss < best_loss:\n",
        "            best_loss = loss\n",
        "            model_save_path = \"/content/drive/MyDrive/MRPRYA002/best1.pth\"\n",
        "            torch.save({\n",
        "                'encoder_state_dict': encoder.state_dict(),\n",
        "                'decoder_state_dict': decoder.state_dict(),\n",
        "                'best_loss': best_loss,\n",
        "            }, model_save_path)\n",
        "            print(f\"Saved new best model with loss {best_loss} at {model_save_path}\")\n",
        "\n",
        "    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxivmTfjwgxg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2QRRrTwwnBd"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])\n",
        "    return decoded_words, decoder_attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5h82OUlwsxI"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUbRS4xpwy61",
        "outputId": "89a9b81a-3125-4f39-f1fc-0dc5ad714db2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "yes\n",
            "['name_x pub english pricerange_x near_x', 'close to near_x name_x pub serves delicious tuscan beef for the pricerange_x price of delicious pub food']\n",
            "Read 42061 sentence pairs\n",
            "Trimmed to 14684 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 23\n",
            "fra 1166\n",
            "0m 35s (- 35m 13s) (1 1%) 2.0676\n",
            "Saved new best model with loss 2.0675674747018253 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "1m 9s (- 33m 30s) (2 3%) 1.3937\n",
            "Saved new best model with loss 1.3937136443871558 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "1m 41s (- 32m 5s) (3 5%) 1.2465\n",
            "Saved new best model with loss 1.246468377399029 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "2m 13s (- 31m 10s) (4 6%) 1.1658\n",
            "Saved new best model with loss 1.1657910967704257 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "2m 45s (- 30m 24s) (5 8%) 1.1068\n",
            "Saved new best model with loss 1.1068235326696325 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "3m 18s (- 29m 48s) (6 10%) 1.0526\n",
            "Saved new best model with loss 1.0526273478479946 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "3m 51s (- 29m 10s) (7 11%) 1.0061\n",
            "Saved new best model with loss 1.006141227120148 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "4m 23s (- 28m 31s) (8 13%) 0.9640\n",
            "Saved new best model with loss 0.9640181558064645 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "4m 55s (- 27m 53s) (9 15%) 0.9244\n",
            "Saved new best model with loss 0.9243818881854512 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "5m 27s (- 27m 15s) (10 16%) 0.8867\n",
            "Saved new best model with loss 0.8866564302273046 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "5m 58s (- 26m 38s) (11 18%) 0.8524\n",
            "Saved new best model with loss 0.8523823185813713 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "6m 30s (- 26m 2s) (12 20%) 0.8214\n",
            "Saved new best model with loss 0.8213530055577979 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "7m 2s (- 25m 28s) (13 21%) 0.7955\n",
            "Saved new best model with loss 0.7954623540761944 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "7m 34s (- 24m 53s) (14 23%) 0.7713\n",
            "Saved new best model with loss 0.7712867111941568 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "8m 6s (- 24m 18s) (15 25%) 0.7452\n",
            "Saved new best model with loss 0.7451974964479475 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "8m 38s (- 23m 45s) (16 26%) 0.7277\n",
            "Saved new best model with loss 0.7276635014153774 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "9m 10s (- 23m 11s) (17 28%) 0.7095\n",
            "Saved new best model with loss 0.7095004677253092 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "9m 42s (- 22m 38s) (18 30%) 0.6899\n",
            "Saved new best model with loss 0.689851946755432 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "10m 14s (- 22m 6s) (19 31%) 0.6746\n",
            "Saved new best model with loss 0.6746067468701884 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "10m 46s (- 21m 33s) (20 33%) 0.6642\n",
            "Saved new best model with loss 0.66422853808777 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "11m 18s (- 21m 0s) (21 35%) 0.6533\n",
            "Saved new best model with loss 0.6532847421621185 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "11m 51s (- 20m 28s) (22 36%) 0.6421\n",
            "Saved new best model with loss 0.6421121317641667 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "12m 23s (- 19m 56s) (23 38%) 0.6310\n",
            "Saved new best model with loss 0.6310100419394071 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "12m 56s (- 19m 24s) (24 40%) 0.6230\n",
            "Saved new best model with loss 0.6229630700578357 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "13m 27s (- 18m 51s) (25 41%) 0.6154\n",
            "Saved new best model with loss 0.6154373942636976 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "14m 0s (- 18m 18s) (26 43%) 0.6130\n",
            "Saved new best model with loss 0.6130049675703049 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "14m 32s (- 17m 46s) (27 45%) 0.6053\n",
            "Saved new best model with loss 0.6053205354540956 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "15m 4s (- 17m 13s) (28 46%) 0.5988\n",
            "Saved new best model with loss 0.5988267654622043 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "15m 36s (- 16m 41s) (29 48%) 0.5927\n",
            "Saved new best model with loss 0.5926733679890892 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "16m 8s (- 16m 8s) (30 50%) 0.5910\n",
            "Saved new best model with loss 0.5910272643716766 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "16m 40s (- 15m 35s) (31 51%) 0.5863\n",
            "Saved new best model with loss 0.5862503205963729 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "17m 11s (- 15m 2s) (32 53%) 0.5815\n",
            "Saved new best model with loss 0.5815242704872472 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "17m 43s (- 14m 30s) (33 55%) 0.5773\n",
            "Saved new best model with loss 0.5772583771634985 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "18m 15s (- 13m 57s) (34 56%) 0.5776\n",
            "18m 47s (- 13m 25s) (35 58%) 0.5759\n",
            "Saved new best model with loss 0.575920494520846 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "19m 19s (- 12m 52s) (36 60%) 0.5747\n",
            "Saved new best model with loss 0.5746847602147163 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "19m 51s (- 12m 20s) (37 61%) 0.5710\n",
            "Saved new best model with loss 0.5710209559381397 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "20m 23s (- 11m 48s) (38 63%) 0.5714\n",
            "20m 54s (- 11m 15s) (39 65%) 0.5723\n",
            "21m 26s (- 10m 43s) (40 66%) 0.5657\n",
            "Saved new best model with loss 0.565651212447609 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "21m 59s (- 10m 11s) (41 68%) 0.5671\n",
            "22m 31s (- 9m 39s) (42 70%) 0.5651\n",
            "Saved new best model with loss 0.5650924227985681 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "23m 3s (- 9m 6s) (43 71%) 0.5644\n",
            "Saved new best model with loss 0.5644286581698585 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "23m 34s (- 8m 34s) (44 73%) 0.5645\n",
            "24m 6s (- 8m 2s) (45 75%) 0.5624\n",
            "Saved new best model with loss 0.5624002850977684 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "24m 38s (- 7m 29s) (46 76%) 0.5623\n",
            "Saved new best model with loss 0.5623116381872194 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "25m 10s (- 6m 57s) (47 78%) 0.5634\n",
            "25m 41s (- 6m 25s) (48 80%) 0.5633\n",
            "26m 13s (- 5m 53s) (49 81%) 0.5633\n",
            "26m 45s (- 5m 21s) (50 83%) 0.5611\n",
            "Saved new best model with loss 0.5611406103393352 at /content/drive/MyDrive/MRPRYA002/best1.pth\n",
            "27m 17s (- 4m 48s) (51 85%) 0.5624\n",
            "27m 49s (- 4m 16s) (52 86%) 0.5623\n",
            "28m 20s (- 3m 44s) (53 88%) 0.5632\n",
            "28m 52s (- 3m 12s) (54 90%) 0.5621\n",
            "29m 24s (- 2m 40s) (55 91%) 0.5638\n",
            "29m 56s (- 2m 8s) (56 93%) 0.5615\n",
            "30m 27s (- 1m 36s) (57 95%) 0.5657\n",
            "30m 59s (- 1m 4s) (58 96%) 0.5691\n",
            "31m 30s (- 0m 32s) (59 98%) 0.5653\n",
            "32m 2s (- 0m 0s) (60 100%) 0.5681\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 256\n",
        "batch_size = 16\n",
        "num_layers = 3  # Number of layers\n",
        "\n",
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size,num_layers = num_layers).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "train(train_dataloader, encoder, decoder, 60, print_every=1, plot_every=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkVq0bvM1gOi",
        "outputId": "b3ea7c44-831e-4db1-8fef-a76849ae5712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> name_x japanese city centre\n",
            "= name_x is a restaurant in the centre of the city which serves japanese food\n",
            "< customer rate in the city centre <EOS>\n",
            "\n",
            "> name_x pricerange_x customerrating_x riverside near_x\n",
            "= highly priced name_x near near_x in riverside has a high rating\n",
            "< SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS\n",
            "\n",
            "> name_x restaurant customerrating_x near_x\n",
            "= near near_x there is a restaurant named name_x and it is rated out of\n",
            "< SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS\n",
            "\n",
            "> name_x fast food pricerange_x customerrating_x\n",
            "= name_x has average fast food for pricerange_x\n",
            "< name_x is a moderately priced fast food restaurant <EOS>\n",
            "\n",
            "> name_x french pricerange_x yes near_x\n",
            "= name_x is a kid friendly pricerange_xly priced french eatery near near_x\n",
            "< near near_x is a family friendly place called name_x <EOS>\n",
            "\n",
            "> name_x japanese pricerange_x riverside\n",
            "= for japanese food costing pricerange_x go to name_x in riverside\n",
            "< north of the town of town called name_x <EOS>\n",
            "\n",
            "> name_x restaurant french customerrating_x\n",
            "= name_x is a french restaurant that has been given a one star rating\n",
            "< eat at name_x <EOS>\n",
            "\n",
            "> name_x french pricerange_x customerrating_x\n",
            "= name_x budget food and drink star\n",
            "< the high price range is name_x <EOS>\n",
            "\n",
            "> name_x chinese pricerange_x city centre near_x\n",
            "= near near_x in the city centre name_x serves pricerange_x priced chinese food\n",
            "< chines dishes from pricerange_x near city centre <EOS>\n",
            "\n",
            "> name_x restaurant customerrating_x no\n",
            "= name_x is a non family friendly restaurant with a customer rating of out of\n",
            "< name_x is a non family friendly restaurant <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "evaluateRandomly(encoder, decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E68z86yhPB7b",
        "outputId": "7bf852d2-d74c-4ebe-e684-bd43bdfc58e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "yes\n",
            "['name_x pub english pricerange_x near_x', 'close to near_x name_x pub serves delicious tuscan beef for the pricerange_x price of delicious pub food']\n",
            "Read 42061 sentence pairs\n",
            "Trimmed to 14684 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 23\n",
            "fra 1166\n",
            "> name_x italian pricerange_x\n",
            "= the restaurant name_x serves italian food and charges more than pounds\n",
            "< <EOS>\n",
            "\n",
            "> name_x restaurant english pricerange_x yes\n",
            "= name_x is an english food restaurant with pricerange_x prices and a family friendly atmosphere\n",
            "< a child free restaurant that serves pricerange_x english food is name_x <EOS>\n",
            "\n",
            "> name_x pub english yes near_x\n",
            "= near near_x is a kid friendly pub that serves english food named name_x\n",
            "< near_x is an english pub named name_x <EOS>\n",
            "\n",
            "> name_x pub customerrating_x riverside yes\n",
            "= name_x is an average rated family friendly pub in the riverside area\n",
            "< pub to the family <EOS>\n",
            "\n",
            "> name_x french pricerange_x customerrating_x riverside\n",
            "= there is a cheap restaurant name_x located outside of the centre of the city\n",
            "< high priced food at the name_x <EOS>\n",
            "\n",
            "> name_x restaurant fast food pricerange_x\n",
            "= name_x is a sit down type restaurant serving fast food less than\n",
            "< fast food restaurant <EOS>\n",
            "\n",
            "> name_x english pricerange_x riverside\n",
            "= the name_x in riverside serves pricerange_x english food\n",
            "< at pricerange_x price range of english food <EOS>\n",
            "\n",
            "> name_x french pricerange_x near_x\n",
            "= a low priced french food restaurant near near_x is name_x\n",
            "< near near_x serves french food for under <EOS>\n",
            "\n",
            "> name_x english pricerange_x customerrating_x\n",
            "= name_x serves english food for a pricerange_x price but leaves out of customers unsatisfied\n",
            "< rated out of by customers in the price range pricerange_x <EOS>\n",
            "\n",
            "> name_x pricerange_x riverside yes near_x\n",
            "= its less than for family s at name_x near near_x in the riverside area\n",
            "< in riverside and is family friendly <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "hidden_size = 256\n",
        "batch_size = 16\n",
        "\n",
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "# Load the saved model state, mapping it to the current device\n",
        "checkpoint = torch.load('/content/drive/MyDrive/MRPRYA002/best1.pth', map_location=device)\n",
        "encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
        "decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
        "\n",
        "# Set the models to evaluation mode\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "evaluateRandomly(encoder, decoder)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}